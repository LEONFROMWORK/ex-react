#!/usr/bin/env python3
"""
ê°œì„ ëœ í¬ë¡¤ëŸ¬ 1í˜ì´ì§€ í…ŒìŠ¤íŠ¸
"""

from oppadu_crawler_v4_improved import OppaduCrawlerV4Improved

def main():
    crawler = OppaduCrawlerV4Improved()
    
    print("=== ê°œì„ ëœ í¬ë¡¤ëŸ¬ (v4 improved) 1í˜ì´ì§€ í…ŒìŠ¤íŠ¸ ===")
    print("ê¸°ì¡´ v4 ë² ì´ìŠ¤ + ê°œì„ ëœ ì‹œê°„ ì •ë³´ ì œê±°")
    print("ë‹µë³€ ê¸¸ì´: 30-600ì (ì±„íƒë‹µë³€), 40-500ì (ì¼ë°˜ë‹µë³€)")
    print()
    
    total_collected = crawler.crawl_pages(
        start_page=1, 
        end_page=1, 
        output_file='../data/oppadu_test_improved.jsonl'
    )
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {total_collected}ê°œ ìˆ˜ì§‘")
    
    if total_collected > 0:
        print("\nğŸ“Š ë°ì´í„° í’ˆì§ˆ í™•ì¸:")
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì½ê¸°
        import json
        with open('../data/oppadu_test_improved.jsonl', 'r', encoding='utf-8') as f:
            test_data = [json.loads(line) for line in f]
        
        print(f"ìˆ˜ì§‘ëœ í•­ëª©: {len(test_data)}ê°œ")
        if test_data:
            avg_q_len = sum(len(item['question']) for item in test_data) / len(test_data)
            avg_a_len = sum(len(item['answer']) for item in test_data) / len(test_data)
            print(f"í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {avg_q_len:.0f}ì")
            print(f"í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_a_len:.0f}ì")
            
            print(f"\nğŸ” ì²« ë²ˆì§¸ í•­ëª© ë¯¸ë¦¬ë³´ê¸°:")
            print(f"ì§ˆë¬¸: {test_data[0]['question'][:100]}...")
            print(f"ë‹µë³€: {test_data[0]['answer'][:100]}...")
        
        print("\nğŸš€ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ì „ì²´ ìˆ˜ì§‘ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        print("ì „ì²´ ìˆ˜ì§‘ ëª…ë ¹ì–´:")
        print("python3 oppadu_crawler_v4_improved.py &")

if __name__ == "__main__":
    main() 