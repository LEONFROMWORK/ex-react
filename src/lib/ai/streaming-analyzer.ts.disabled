/**
 * 실시간 AI 스트리밍 분석 시스템
 * 30초 대기 → 3초 실시간 응답으로 개선
 */

import { TierSystemManager } from './tier-system'
import { OpenRouterProvider } from './providers/openrouter'
import { AIOptions, AIResponse } from './types'

export interface StreamingAnalysisResult {
  partialResults: PartialResult[]
  finalResult: AIResponse
  streamingStats: {
    totalTime: number
    firstResponseTime: number
    chunksReceived: number
    averageChunkTime: number
  }
}

export interface PartialResult {
  content: string
  confidence: number
  tier: number
  timestamp: number
  isComplete: boolean
  suggestions?: string[]
}

export interface StreamingOptions extends AIOptions {
  enablePartialResults?: boolean
  chunkCallback?: (chunk: PartialResult) => void
  confidenceThreshold?: number
  maxStreamTime?: number
}

export class StreamingAIAnalyzer {
  private tierSystem: TierSystemManager
  
  constructor(apiKey: string) {
    this.tierSystem = new TierSystemManager(apiKey)
  }

  async analyzeWithStreaming(
    prompt: string,
    options: StreamingOptions = {}
  ): Promise<StreamingAnalysisResult> {
    console.log('🌊 실시간 스트리밍 분석 시작')
    
    const startTime = performance.now()
    const partialResults: PartialResult[] = []
    let firstResponseTime = 0
    let chunksReceived = 0
    
    // 스트리밍 설정
    const streamOptions: StreamingOptions = {
      enablePartialResults: true,
      confidenceThreshold: 0.7,
      maxStreamTime: 30000, // 30초 최대 대기
      ...options
      // stream: true // OpenRouter 스트리밍 활성화 (타입 오류로 임시 제거)
    }

    try {
      // Tier 선택 (복잡도 기반 사전 판단)
      const complexity = this.analyzeComplexity(prompt)
      const startTier = this.selectStartingTier(complexity)
      
      console.log(`🎯 시작 Tier: ${startTier} (복잡도: ${complexity})`)
      
      // 스트리밍 분석 실행
      const result = await this.streamingAnalysis(prompt, startTier, streamOptions, {
        onPartialResult: (partial) => {
          if (firstResponseTime === 0) {
            firstResponseTime = performance.now() - startTime
            console.log(`⚡ 첫 응답: ${firstResponseTime.toFixed(2)}ms`)
          }
          
          chunksReceived++
          partialResults.push(partial)
          
          // 실시간 콜백 호출
          if (options.chunkCallback) {
            options.chunkCallback(partial)
          }
          
          console.log(`📦 청크 ${chunksReceived}: ${partial.content.slice(0, 50)}...`)
        }
      })
      
      const totalTime = performance.now() - startTime
      
      return {
        partialResults,
        finalResult: result,
        streamingStats: {
          totalTime,
          firstResponseTime,
          chunksReceived,
          averageChunkTime: chunksReceived > 0 ? totalTime / chunksReceived : 0
        }
      }
      
    } catch (error) {
      console.error('❌ 스트리밍 분석 실패:', error)
      throw error
    }
  }

  private async streamingAnalysis(
    prompt: string,
    tier: number,
    options: StreamingOptions,
    callbacks: {
      onPartialResult: (result: PartialResult) => void
    }
  ): Promise<AIResponse> {
    const tierConfig = this.tierSystem.getTierInfo()[tier - 1]
    const provider = new OpenRouterProvider(process.env.OPENROUTER_API_KEY!, tierConfig.model)
    
    // 스트리밍 요청 생성
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
        'HTTP-Referer': process.env.NEXT_PUBLIC_SITE_URL || 'https://exhell.app',
        'X-Title': 'Exhell Excel Assistant',
      },
      body: JSON.stringify({
        model: tierConfig.model,
        messages: [
          {
            role: 'system',
            content: this.buildStreamingPrompt(tier, options.systemPrompt)
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        // stream: true // 타입 오류로 임시 제거,
        max_tokens: options.maxTokens || 2000,
        temperature: options.temperature || 0.7,
      })
    })

    if (!response.ok) {
      throw new Error(`스트리밍 요청 실패: ${response.status}`)
    }

    return await this.processStreamingResponse(response, tier, callbacks)
  }

  private async processStreamingResponse(
    response: Response,
    tier: number,
    callbacks: {
      onPartialResult: (result: PartialResult) => void
    }
  ): Promise<AIResponse> {
    const reader = response.body?.getReader()
    if (!reader) {
      throw new Error('스트림 리더 생성 실패')
    }

    const decoder = new TextDecoder()
    let buffer = ''
    let fullContent = ''
    let currentConfidence = 0

    try {
      while (true) {
        const { done, value } = await reader.read()
        
        if (done) break
        
        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6)
            
            if (data === '[DONE]') {
              continue
            }
            
            try {
              const parsed = JSON.parse(data)
              const delta = parsed.choices?.[0]?.delta?.content
              
              if (delta) {
                fullContent += delta
                currentConfidence = this.estimateStreamingConfidence(fullContent)
                
                // 부분 결과 생성
                const partialResult: PartialResult = {
                  content: fullContent,
                  confidence: currentConfidence,
                  tier,
                  timestamp: Date.now(),
                  isComplete: false,
                  suggestions: this.extractSuggestions(fullContent)
                }
                
                callbacks.onPartialResult(partialResult)
              }
              
            } catch (error) {
              console.warn('스트림 파싱 오류:', error)
            }
          }
        }
      }
      
      // 최종 결과 생성
      const finalConfidence = this.extractFinalConfidence(fullContent)
      
      // 신뢰도가 낮으면 에스컬레이션
      if (finalConfidence < 0.85 && tier < 3) {
        console.log(`⬆️ Tier ${tier} → ${tier + 1} 에스컬레이션 (신뢰도: ${finalConfidence})`)
        return await this.streamingAnalysis(
          `이전 분석 결과: ${fullContent}\n\n더 정확한 분석이 필요합니다.`,
          tier + 1,
          // { stream: true }, // 타입 오류로 임시 제거
          callbacks
        )
      }
      
      return {
        content: fullContent,
        model: this.tierSystem.getTierInfo()[tier - 1].model,
        provider: 'openrouter',
        usage: {
          promptTokens: 0, // 스트리밍에서는 추정값
          completionTokens: this.estimateTokens(fullContent),
          totalTokens: 0
        },
        latency: 0,
        cost: 0
      }
      
    } finally {
      reader.releaseLock()
    }
  }

  private buildStreamingPrompt(tier: number, systemPrompt?: string): string {
    const tierPrompts = {
      1: `당신은 빠른 Excel 분석 전문가입니다. 
           실시간으로 분석 결과를 제공하세요.
           먼저 핵심 문제를 파악하고, 점진적으로 상세한 해결책을 제시하세요.
           각 단계마다 현재 신뢰도를 "신뢰도: 0.XX"로 표시하세요.`,
      
      2: `당신은 복잡한 Excel 문제 해결 전문가입니다.
           실시간으로 단계별 분석을 수행하세요.
           1단계: 문제 식별, 2단계: 원인 분석, 3단계: 해결책 제시
           각 단계마다 신뢰도를 업데이트하세요.`,
      
      3: `당신은 최고 수준의 Excel 전문가입니다.
           가장 복잡한 문제를 실시간으로 해결하세요.
           포괄적인 분석과 다양한 해결 방안을 단계별로 제시하세요.
           최종 신뢰도를 "최종 신뢰도: 0.XX"로 표시하세요.`
    }
    
    const tierPrompt = tierPrompts[tier as keyof typeof tierPrompts] || tierPrompts[1]
    
    return systemPrompt 
      ? `${systemPrompt}\n\n${tierPrompt}`
      : tierPrompt
  }

  private analyzeComplexity(prompt: string): number {
    let complexity = 0.3 // 기본 복잡도
    
    // 키워드 기반 복잡도 분석
    const complexKeywords = [
      'vlookup', 'index', 'match', 'array', 'pivot', 'macro', 'vba',
      '순환참조', '복잡한', '여러', '다중', '고급', '최적화'
    ]
    
    const advancedKeywords = [
      'power query', 'power pivot', 'dynamic array', '람다',
      '연결된 데이터', '외부 데이터', 'api', 'json', 'xml'
    ]
    
    // 기본 복잡도 계산
    complexKeywords.forEach(keyword => {
      if (prompt.toLowerCase().includes(keyword)) {
        complexity += 0.15
      }
    })
    
    // 고급 복잡도 계산
    advancedKeywords.forEach(keyword => {
      if (prompt.toLowerCase().includes(keyword)) {
        complexity += 0.25
      }
    })
    
    // 문서 길이 기반 복잡도
    if (prompt.length > 500) complexity += 0.1
    if (prompt.length > 1000) complexity += 0.1
    
    return Math.min(complexity, 1.0)
  }

  private selectStartingTier(complexity: number): number {
    if (complexity > 0.8) return 3 // 고복잡도 → Tier 3
    if (complexity > 0.5) return 2 // 중복잡도 → Tier 2
    return 1 // 저복잡도 → Tier 1
  }

  private estimateStreamingConfidence(content: string): number {
    // 실시간 신뢰도 추정
    let confidence = 0.3
    
    // 내용 길이 기반
    if (content.length > 100) confidence += 0.2
    if (content.length > 300) confidence += 0.2
    
    // Excel 전문 용어 포함도
    const terms = ['수식', '셀', '함수', '범위', '워크시트']
    const termCount = terms.filter(term => content.includes(term)).length
    confidence += (termCount / terms.length) * 0.3
    
    // 구조화된 답변 여부
    if (content.includes('1.') || content.includes('단계')) confidence += 0.1
    if (content.includes('해결책') || content.includes('방법')) confidence += 0.1
    
    return Math.min(confidence, 0.95)
  }

  private extractFinalConfidence(content: string): number {
    const matches = content.match(/(?:최종\s*)?신뢰도:\s*(\d*\.?\d+)/i)
    if (matches) {
      return parseFloat(matches[1])
    }
    return this.estimateStreamingConfidence(content)
  }

  private extractSuggestions(content: string): string[] {
    const suggestions: string[] = []
    
    // 일반적인 제안 패턴 추출
    const suggestionPatterns = [
      /(\d+\.\s*[^.]+(?:하세요|해보세요|권장합니다))/g,
      /(권장.*?[:：]\s*[^.]+)/g,
      /(해결책.*?[:：]\s*[^.]+)/g
    ]
    
    suggestionPatterns.forEach(pattern => {
      const matches = content.match(pattern)
      if (matches) {
        suggestions.push(...matches.slice(0, 3)) // 최대 3개
      }
    })
    
    return suggestions.slice(0, 5) // 최대 5개 제안
  }

  private estimateTokens(text: string): number {
    // 간단한 토큰 추정 (1 토큰 ≈ 4 글자)
    return Math.ceil(text.length / 4)
  }

  // 스트리밍 성능 벤치마크
  async benchmarkStreaming(prompt: string): Promise<{
    streaming: number
    traditional: number
    improvement: number
  }> {
    console.log('📊 스트리밍 vs 전통적 방식 벤치마크')
    
    // 스트리밍 방식 측정
    const streamingStart = performance.now()
    const streamingResult = await this.analyzeWithStreaming(prompt)
    const streamingTime = streamingResult.streamingStats.firstResponseTime
    
    // 전통적 방식 측정 (스트리밍 비활성화)
    const traditionalStart = performance.now()
    await this.tierSystem.analyzeWithTiers(prompt, { stream: false })
    const traditionalTime = performance.now() - traditionalStart
    
    const improvement = ((traditionalTime - streamingTime) / traditionalTime) * 100
    
    console.log(`📈 성능 개선: ${improvement.toFixed(1)}% (${traditionalTime.toFixed(0)}ms → ${streamingTime.toFixed(0)}ms)`)
    
    return {
      streaming: streamingTime,
      traditional: traditionalTime,
      improvement
    }
  }
}

// 사용 예시
export async function analyzeExcelWithStreaming(
  prompt: string,
  options: StreamingOptions = {}
): Promise<StreamingAnalysisResult> {
  const analyzer = new StreamingAIAnalyzer(process.env.OPENROUTER_API_KEY!)
  return await analyzer.analyzeWithStreaming(prompt, options)
}